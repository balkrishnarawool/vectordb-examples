server.port=8000
spring.threads.virtual.enabled=true

#spring.ai.ollama.base-url=localhost:11434
#Default url is localhost:11434. So no need to set.

#spring.ai.ollama.embedding.enabled=true\
#It is enabled by default.

spring.ai.ollama.embedding.options.model=llama2
#Default model is mistral. But we are running llama2. So changed here.

spring.datasource.password=postgres
spring.datasource.username=postgres
spring.datasource.url=jdbc:postgresql://localhost/vector_store

#spring.ai.vectorstore.pgvector.index-type=HNSW
spring.ai.vectorstore.pgvector.index-type=NONE
#Indexing is disabled because the llama2 embedding model produces embeddings with dimension 4096 and pgvector cannot index vectors with more than 2000 dimensions.


